{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7dad59",
   "metadata": {},
   "source": [
    "Mengolah dan menyiapkan data anotasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b0163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fe0a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fe0a9_level0_col0\" class=\"col_heading level0 col0\" >subject_id</th>\n",
       "      <th id=\"T_fe0a9_level0_col1\" class=\"col_heading level0 col1\" >name</th>\n",
       "      <th id=\"T_fe0a9_level0_col2\" class=\"col_heading level0 col2\" >gender</th>\n",
       "      <th id=\"T_fe0a9_level0_col3\" class=\"col_heading level0 col3\" >label_before</th>\n",
       "      <th id=\"T_fe0a9_level0_col4\" class=\"col_heading level0 col4\" >label_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0a9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fe0a9_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_fe0a9_row0_col1\" class=\"data row0 col1\" >aaisyah_nursalsabiil_ni_patriarti</td>\n",
       "      <td id=\"T_fe0a9_row0_col2\" class=\"data row0 col2\" >P</td>\n",
       "      <td id=\"T_fe0a9_row0_col3\" class=\"data row0 col3\" >anxiety</td>\n",
       "      <td id=\"T_fe0a9_row0_col4\" class=\"data row0 col4\" >anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0a9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fe0a9_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_fe0a9_row1_col1\" class=\"data row1 col1\" >abdul_aziz</td>\n",
       "      <td id=\"T_fe0a9_row1_col2\" class=\"data row1 col2\" >L</td>\n",
       "      <td id=\"T_fe0a9_row1_col3\" class=\"data row1 col3\" >non-anxiety</td>\n",
       "      <td id=\"T_fe0a9_row1_col4\" class=\"data row1 col4\" >non-anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0a9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fe0a9_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_fe0a9_row2_col1\" class=\"data row2 col1\" >ahmad_rifqi_hendriansyah</td>\n",
       "      <td id=\"T_fe0a9_row2_col2\" class=\"data row2 col2\" >L</td>\n",
       "      <td id=\"T_fe0a9_row2_col3\" class=\"data row2 col3\" >anxiety</td>\n",
       "      <td id=\"T_fe0a9_row2_col4\" class=\"data row2 col4\" >non-anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0a9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fe0a9_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_fe0a9_row3_col1\" class=\"data row3 col1\" >aida_rahma_fadhila</td>\n",
       "      <td id=\"T_fe0a9_row3_col2\" class=\"data row3 col2\" >P</td>\n",
       "      <td id=\"T_fe0a9_row3_col3\" class=\"data row3 col3\" >anxiety</td>\n",
       "      <td id=\"T_fe0a9_row3_col4\" class=\"data row3 col4\" >non-anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0a9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fe0a9_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_fe0a9_row4_col1\" class=\"data row4 col1\" >akhmad_aakhif_athallah</td>\n",
       "      <td id=\"T_fe0a9_row4_col2\" class=\"data row4 col2\" >L</td>\n",
       "      <td id=\"T_fe0a9_row4_col3\" class=\"data row4 col3\" >non-anxiety</td>\n",
       "      <td id=\"T_fe0a9_row4_col4\" class=\"data row4 col4\" >non-anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72110492dd20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ANNOTATION_PATH = os.path.join(Path.home(), \"datasets\", \"primary-converted\", \"OLAH DATA.xlsx\")\n",
    "\n",
    "dfs = pd.read_excel(ANNOTATION_PATH, sheet_name=[\"8-12-2025\", \"9-12-2025\"], engine=\"openpyxl\")\n",
    "\n",
    "df8 = dfs[\"8-12-2025\"]\n",
    "df9 = dfs[\"9-12-2025\"]\n",
    "\n",
    "df8_cleaned = pd.DataFrame({\n",
    "    \"subject_id\": df8[\"NO\"].astype(int),\n",
    "    \"name\": df8[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df8[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label_before\": df8[\"LABEL BEFORE\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "    \"label_after\": df8[\"LABEL AFTER\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df9_cleaned = pd.DataFrame({\n",
    "    \"subject_id\": df9[\"NO\"].astype(int),\n",
    "    \"name\": df9[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df9[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label_before\": df9[\"LABEL BEFORE\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "    \"label_after\": df9[\"LABEL AFTER\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df8_cleaned.head().style.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8afcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "target_path = os.path.join(Path.cwd(), \"..\", \"formatted-annotations.xlsx\")\n",
    "\n",
    "# Combine the two dataframes into one single csv with different sheets\n",
    "with pd.ExcelWriter(target_path, engine=\"openpyxl\") as writer:\n",
    "    df8_cleaned.to_excel(writer, sheet_name=\"8-12-2025\", index=False)\n",
    "    df9_cleaned.to_excel(writer, sheet_name=\"9-12-2025\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31daa2e5",
   "metadata": {},
   "source": [
    "Mengolah data berdasarkan time series before dan after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e34dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_60ead\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_60ead_level0_col0\" class=\"col_heading level0 col0\" >subject_id</th>\n",
       "      <th id=\"T_60ead_level0_col1\" class=\"col_heading level0 col1\" >name</th>\n",
       "      <th id=\"T_60ead_level0_col2\" class=\"col_heading level0 col2\" >gender</th>\n",
       "      <th id=\"T_60ead_level0_col3\" class=\"col_heading level0 col3\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60ead_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_60ead_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_60ead_row0_col1\" class=\"data row0 col1\" >aaisyah_nursalsabiil_ni_patriarti</td>\n",
       "      <td id=\"T_60ead_row0_col2\" class=\"data row0 col2\" >P</td>\n",
       "      <td id=\"T_60ead_row0_col3\" class=\"data row0 col3\" >anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60ead_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_60ead_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_60ead_row1_col1\" class=\"data row1 col1\" >abdul_aziz</td>\n",
       "      <td id=\"T_60ead_row1_col2\" class=\"data row1 col2\" >L</td>\n",
       "      <td id=\"T_60ead_row1_col3\" class=\"data row1 col3\" >non-anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60ead_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_60ead_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_60ead_row2_col1\" class=\"data row2 col1\" >ahmad_rifqi_hendriansyah</td>\n",
       "      <td id=\"T_60ead_row2_col2\" class=\"data row2 col2\" >L</td>\n",
       "      <td id=\"T_60ead_row2_col3\" class=\"data row2 col3\" >anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60ead_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_60ead_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_60ead_row3_col1\" class=\"data row3 col1\" >aida_rahma_fadhila</td>\n",
       "      <td id=\"T_60ead_row3_col2\" class=\"data row3 col2\" >P</td>\n",
       "      <td id=\"T_60ead_row3_col3\" class=\"data row3 col3\" >anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60ead_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_60ead_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_60ead_row4_col1\" class=\"data row4 col1\" >akhmad_aakhif_athallah</td>\n",
       "      <td id=\"T_60ead_row4_col2\" class=\"data row4 col2\" >L</td>\n",
       "      <td id=\"T_60ead_row4_col3\" class=\"data row4 col3\" >non-anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7211048ebac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_ANNOTATION_PATH = os.path.join(Path.home(), \"datasets\", \"primary-converted\", \"OLAH DATA.xlsx\")\n",
    "\n",
    "dfs = pd.read_excel(BASE_ANNOTATION_PATH, sheet_name=[\"8-12-2025\", \"9-12-2025\"], engine=\"openpyxl\")\n",
    "\n",
    "df8_before = dfs[\"8-12-2025\"]\n",
    "df8_after  = dfs[\"8-12-2025\"]\n",
    "df9_before = dfs[\"9-12-2025\"]\n",
    "df9_after  = dfs[\"9-12-2025\"]\n",
    "\n",
    "df8_before = pd.DataFrame({\n",
    "    \"subject_id\": df8_before[\"NO\"].astype(int),\n",
    "    \"name\": df8_before[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df8_before[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label\": df8_before[\"LABEL BEFORE\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df8_after = pd.DataFrame({\n",
    "    \"subject_id\": df8_after[\"NO\"].astype(int),\n",
    "    \"name\": df8_after[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df8_after[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label\": df8_after[\"LABEL AFTER\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df9_before = pd.DataFrame({\n",
    "    \"subject_id\": df9_before[\"NO\"].astype(int),\n",
    "    \"name\": df9_before[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df9_before[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label\": df9_before[\"LABEL BEFORE\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df9_after = pd.DataFrame({\n",
    "    \"subject_id\": df9_after[\"NO\"].astype(int),\n",
    "    \"name\": df9_after[\"NAMA\"].astype(str).str.strip().str.lower().str.replace(' ', '_'),\n",
    "    \"gender\": df9_after[\"JK\"].astype(str).str.strip().str.upper(),\n",
    "    \"label\": df9_after[\"LABEL AFTER\"].str.strip().str.lower().apply(\n",
    "        lambda x: \"anxiety\" if x == \"cemas\" else \"non-anxiety\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "df8_before.head().style.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bad66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "target_path = os.path.join(Path.cwd(), \"..\", \"formatted-time-series-annotations.xlsx\")\n",
    "\n",
    "# Combine the two dataframes into one single csv with different sheets\n",
    "with pd.ExcelWriter(target_path, engine=\"openpyxl\") as writer:\n",
    "    df8_before.to_excel(writer, sheet_name=\"before-8\", index=False)\n",
    "    df8_after.to_excel(writer, sheet_name=\"after-8\", index=False)\n",
    "    df9_before.to_excel(writer, sheet_name=\"before-9\", index=False)\n",
    "    df9_after.to_excel(writer, sheet_name=\"after-9\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47124b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_455a4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_455a4_level0_col0\" class=\"col_heading level0 col0\" >subject_id</th>\n",
       "      <th id=\"T_455a4_level0_col1\" class=\"col_heading level0 col1\" >name</th>\n",
       "      <th id=\"T_455a4_level0_col2\" class=\"col_heading level0 col2\" >gender</th>\n",
       "      <th id=\"T_455a4_level0_col3\" class=\"col_heading level0 col3\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_455a4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_455a4_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_455a4_row0_col1\" class=\"data row0 col1\" >aaisyah_nursalsabiil_ni_patriarti</td>\n",
       "      <td id=\"T_455a4_row0_col2\" class=\"data row0 col2\" >P</td>\n",
       "      <td id=\"T_455a4_row0_col3\" class=\"data row0 col3\" >anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_455a4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_455a4_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_455a4_row1_col1\" class=\"data row1 col1\" >abdul_aziz</td>\n",
       "      <td id=\"T_455a4_row1_col2\" class=\"data row1 col2\" >L</td>\n",
       "      <td id=\"T_455a4_row1_col3\" class=\"data row1 col3\" >non-anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x74baec3b8250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyiapkan dataset menggunakan anotasi yang telah diformat pada `data-preparation.ipynb`\n",
    "# Anotasi yang telah dibersihkan memberikan format yang lebih konsisten dan memudahkan proses pengolahan\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "annotation_path = os.path.join(Path.cwd(), \"..\", \"formatted-time-series-annotations.xlsx\")\n",
    "\n",
    "dfs = pd.read_excel(annotation_path, sheet_name=None)\n",
    "\n",
    "df8_before = dfs[\"before-8\"]\n",
    "df8_after  = dfs[\"after-8\"]\n",
    "df9_before = dfs[\"before-9\"]\n",
    "df9_after  = dfs[\"after-9\"]\n",
    "\n",
    "df8_before.head(2).style.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b62a36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512', 'anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/abdul_aziz_1765185030009', 'non-anxiety')]\n",
      "[('/home/inadio/datasets/primary-converted/AFTER 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765170495474', 'anxiety'), ('/home/inadio/datasets/primary-converted/AFTER 8-12-2025/abdul_aziz_1765187125263', 'non-anxiety')]\n",
      "[('/home/inadio/datasets/primary-converted/BEFORE 9-12-2025/abdillah_agil_arbiansyah_1765266493607', 'non-anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 9-12-2025/achmad_anfasa_rabbany_1765271116146', 'anxiety')]\n",
      "[('/home/inadio/datasets/primary-converted/AFTER 9-12-2025/abdillah_agil_arbiansyah_1765270077268', 'non-anxiety'), ('/home/inadio/datasets/primary-converted/AFTER 9-12-2025/achmad_anfasa_rabbany_1765273715027', 'non-anxiety')]\n"
     ]
    }
   ],
   "source": [
    "# Mengambil keseluruhan data yang siap digunakan disesuaikan dengan notasi yang telah dirapikan\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "DATASOURCE_ROOT_PATH = os.path.join(Path.home(), \"datasets\", \"primary-converted\")\n",
    "\n",
    "DATASOURCE_GROUP_SUBJECT_ONE_BEFORE = os.path.join(DATASOURCE_ROOT_PATH, \"BEFORE 8-12-2025\")\n",
    "\n",
    "DATASOURCE_GROUP_SUBJECT_ONE_AFTER = os.path.join(DATASOURCE_ROOT_PATH, \"AFTER 8-12-2025\")\n",
    "\n",
    "DATASOURCE_GROUP_SUBJECT_TWO_BEFORE = os.path.join(DATASOURCE_ROOT_PATH, \"BEFORE 9-12-2025\")\n",
    "\n",
    "DATASOURCE_GROUP_SUBJECT_TWO_AFTER = os.path.join(DATASOURCE_ROOT_PATH, \"AFTER 9-12-2025\")\n",
    "\n",
    "\n",
    "# Memasangkan anotasi dengan data yang sesuai untuk setiap subjek dalam kedua grup\n",
    "# Hasil akhir adalah dua list yang berisi tuple (path_data, label)\n",
    "def prepare_dataset(df: pd.DataFrame, group_path: str) -> list[tuple[str, int]]:\n",
    "    dataset = []\n",
    "    \n",
    "    # Validasi apakah path grup ada\n",
    "    # Jika tidak ada, berikan pesan kesalahan yang jelas\n",
    "    if not os.path.exists(group_path):\n",
    "        raise FileNotFoundError(f\"Path does not exist: {group_path}\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        name = row[\"name\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        # Mencari direktori atau file yang cocok pada group_path\n",
    "        for item in os.listdir(group_path):\n",
    "            item_path = os.path.join(group_path, item)\n",
    "            \n",
    "            # Memastikan jika nama subjek sesuai dengan item di direktori\n",
    "            if name.lower() in item.lower() or item.lower() in name.lower():\n",
    "                dataset.append((item_path, label))\n",
    "                break\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_group_one_before = prepare_dataset(df8_before, DATASOURCE_GROUP_SUBJECT_ONE_BEFORE)\n",
    "dataset_group_one_after  = prepare_dataset(df8_after, DATASOURCE_GROUP_SUBJECT_ONE_AFTER)\n",
    "dataset_group_two_before = prepare_dataset(df9_before, DATASOURCE_GROUP_SUBJECT_TWO_BEFORE)\n",
    "dataset_group_two_after  = prepare_dataset(df9_after, DATASOURCE_GROUP_SUBJECT_TWO_AFTER)\n",
    "\n",
    "print(dataset_group_one_before[:2])\n",
    "print(dataset_group_one_after[:2])\n",
    "print(dataset_group_two_before[:2])\n",
    "print(dataset_group_two_after[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc1f3a",
   "metadata": {},
   "source": [
    "Menyimpan data untuk proses training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56965216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points collected: 25\n",
      "[('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512/q1/answer_1_15d591ce-051a-47f2-ac38-367c1e6189c7_sec.avi', 'anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512/q2/answer_2_490a0a4a-d935-4509-9a4e-fb0a393be5b9_sec.avi', 'anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512/q3/answer_3_ce8ef7e8-63e6-46c1-a510-1b8269c27ce7_sec.avi', 'anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512/q4/answer_4_497eb431-dd00-4530-858f-e8ec710014e7_sec.avi', 'anxiety'), ('/home/inadio/datasets/primary-converted/BEFORE 8-12-2025/aaisyah_nursalsabiil_ni_patriarti_1765168488512/q5/answer_5_e1e6b3e5-a2d1-4832-a1fc-e03673252751_sec.avi', 'anxiety')]\n"
     ]
    }
   ],
   "source": [
    "dataset_list = dataset_group_one_before + dataset_group_one_after + dataset_group_two_before + dataset_group_two_after\n",
    "\n",
    "datasource = []\n",
    "\n",
    "# Menggunakan beberapa data pertama sebagai percobaan\n",
    "for data_path, label in dataset_list[:5]:\n",
    "    \n",
    "    # Jika data tidak ditemukan melalui path yang diberikan, lewati untuk saat ini\n",
    "    if not os.path.exists(data_path):\n",
    "        continue\n",
    "\n",
    "    for q_dir in sorted(os.listdir(data_path)):\n",
    "        q_dir_path = os.path.join(data_path, q_dir)\n",
    "\n",
    "        if os.path.isdir(q_dir_path) and q_dir.startswith(\"q\"):\n",
    "            video_files = [f for f in os.listdir(q_dir_path) if f.endswith(\".avi\")]\n",
    "\n",
    "            # Jika ada file video .avi, yang menunjukkan data diambil menggunakan kamera Intel RealSense\n",
    "            # Hanya mengambil satu file video per direktori q*\n",
    "            if video_files:\n",
    "                video_file_path = os.path.join(q_dir_path, video_files[0])\n",
    "                datasource.append((video_file_path, label))\n",
    "\n",
    "print(f\"Total data points collected: {len(datasource)}\")\n",
    "print(datasource[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347698d",
   "metadata": {},
   "source": [
    "Membuat blueprint untuk MicroExpDataSource dengan tujuan memudahkan proses pengolahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class MicroExpDataSource:\n",
    "\n",
    "    DATASOURCE_ROOT_PATH = os.path.join(Path.home(), \"datasets\", \"primary-converted\")\n",
    "\n",
    "    DATASOURCE_GROUP_SUBJECT_ONE_BEFORE = os.path.join(DATASOURCE_ROOT_PATH, \"BEFORE 8-12-2025\")\n",
    "    \n",
    "    DATASOURCE_GROUP_SUBJECT_ONE_AFTER = os.path.join(DATASOURCE_ROOT_PATH, \"AFTER 8-12-2025\")\n",
    "    \n",
    "    DATASOURCE_GROUP_SUBJECT_TWO_BEFORE = os.path.join(DATASOURCE_ROOT_PATH, \"BEFORE 9-12-2025\")\n",
    "    \n",
    "    DATASOURCE_GROUP_SUBJECT_TWO_AFTER = os.path.join(DATASOURCE_ROOT_PATH, \"AFTER 9-12-2025\")\n",
    "\n",
    "    def __init__(self, dataset_list: List[Tuple[str, str]]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_list: Daftar yang terdiri dari (subject_path, label) tuples\n",
    "        \"\"\"\n",
    "        self.datasource = []\n",
    "\n",
    "        annotation_path = os.path.join(Path.cwd(), \"..\", \"formatted-time-series-annotations.xlsx\")\n",
    "        dfs = pd.read_excel(annotation_path, sheet_name=None)\n",
    "\n",
    "        df8_before = dfs[\"before-8\"]\n",
    "        df8_after  = dfs[\"after-8\"]\n",
    "        df9_before = dfs[\"before-9\"]\n",
    "        df9_after  = dfs[\"after-9\"]\n",
    "\n",
    "        dataset_group_one_before = self.__prep(df8_before, self.DATASOURCE_GROUP_SUBJECT_ONE_BEFORE)\n",
    "        dataset_group_one_after  = self.__prep(df8_after, self.DATASOURCE_GROUP_SUBJECT_ONE_AFTER)\n",
    "        dataset_group_two_before = self.__prep(df9_before, self.DATASOURCE_GROUP_SUBJECT_TWO_BEFORE)\n",
    "        dataset_group_two_after  = self.__prep(df9_after, self.DATASOURCE_GROUP_SUBJECT_TWO_AFTER)\n",
    "\n",
    "        dataset_list = dataset_group_one_before + dataset_group_one_after + dataset_group_two_before + dataset_group_two_after\n",
    "\n",
    "        for subject_path, label in dataset_list:\n",
    "            \n",
    "            # Jika data tidak ditemukan melalui path yang diberikan, lewati untuk saat ini\n",
    "            if not os.path.exists(subject_path):\n",
    "                continue\n",
    "\n",
    "            for q_dir in sorted(os.listdir(subject_path)):\n",
    "                q_dir_path = os.path.join(subject_path, q_dir)\n",
    "\n",
    "                if os.path.isdir(q_dir_path) and q_dir.startswith(\"q\"):\n",
    "                    video_files = [f for f in os.listdir(q_dir_path) if f.endswith(\".avi\")]\n",
    "\n",
    "                    # Jika ada file video .avi, yang menunjukkan data diambil menggunakan kamera Intel RealSense\n",
    "                    # Hanya mengambil satu file video per direktori q*\n",
    "                    if video_files:\n",
    "                        video_file_path = os.path.join(q_dir_path, video_files[0])\n",
    "                        self.datasource.append((video_file_path, label))\n",
    "\n",
    "    \n",
    "    def __prep(self, df: pd.DataFrame, group_path: str) -> list[tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Menggabungkan anotasi dengan data yang sesuai untuk setiap subjek dalam grup tertentu.\n",
    "        Hasil akhir adalah list yang berisi tuple (path_data, label).\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame berisi anotasi yang telah dibersihkan.\n",
    "            group_path (str): Path ke direktori grup data subjek.\n",
    "        \n",
    "        Returns:\n",
    "            list[tuple[str, int]]: List berisi tuple (path_data, label).\n",
    "        \"\"\"\n",
    "        dataset = []\n",
    "        \n",
    "        # Validasi apakah path grup ada\n",
    "        # Jika tidak ada, berikan pesan kesalahan yang jelas\n",
    "        if not os.path.exists(group_path):\n",
    "            raise FileNotFoundError(f\"Path does not exist: {group_path}\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            name = row[\"name\"]\n",
    "            label = row[\"label\"]\n",
    "            \n",
    "            # Mencari direktori atau file yang cocok pada group_path\n",
    "            for item in os.listdir(group_path):\n",
    "                item_path = os.path.join(group_path, item)\n",
    "                \n",
    "                # Memastikan jika nama subjek sesuai dengan item di direktori\n",
    "                if name.lower() in item.lower() or item.lower() in name.lower():\n",
    "                    dataset.append((item_path, label))\n",
    "                    break\n",
    "        \n",
    "        return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulse-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
